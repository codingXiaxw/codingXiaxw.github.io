<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Spark," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.2" />






<meta name="description" content="每次接触一个新的知识之前我都抱有恐惧之心，因为总认为自己没有接触到的知识都很高大上，比如上篇介绍到的Hadoop的安装与使用与本篇要介绍的Spark,其实在自己真正琢磨以后才发现本以为高大上的知识其实也不过如此。">
<meta property="og:type" content="article">
<meta property="og:title" content="『 Spark 』mac下Spark的安装与使用">
<meta property="og:url" content="http://codingxiaxw.cn/2016/12/07/60-mac-spark/index.html">
<meta property="og:site_name" content="codingXiaxw's blog">
<meta property="og:description" content="每次接触一个新的知识之前我都抱有恐惧之心，因为总认为自己没有接触到的知识都很高大上，比如上篇介绍到的Hadoop的安装与使用与本篇要介绍的Spark,其实在自己真正琢磨以后才发现本以为高大上的知识其实也不过如此。">
<meta property="og:image" content="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-07%20%E4%B8%8B%E5%8D%883.27.59.png">
<meta property="og:image" content="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-07%20%E4%B8%8B%E5%8D%884.50.39.png">
<meta property="og:image" content="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-07%20%E4%B8%8A%E5%8D%8811.33.53.png">
<meta property="og:image" content="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-07%20%E4%B8%8B%E5%8D%883.56.26.png">
<meta property="og:image" content="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-07%20%E4%B8%8B%E5%8D%883.59.58.png">
<meta property="og:image" content="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-10%20%E4%B8%8B%E5%8D%882.11.20.png">
<meta property="og:image" content="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-10%20%E4%B8%8B%E5%8D%882.42.45.png">
<meta property="og:updated_time" content="2017-02-28T01:57:54.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="『 Spark 』mac下Spark的安装与使用">
<meta name="twitter:description" content="每次接触一个新的知识之前我都抱有恐惧之心，因为总认为自己没有接触到的知识都很高大上，比如上篇介绍到的Hadoop的安装与使用与本篇要介绍的Spark,其实在自己真正琢磨以后才发现本以为高大上的知识其实也不过如此。">
<meta name="twitter:image" content="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-07%20%E4%B8%8B%E5%8D%883.27.59.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://codingxiaxw.cn/2016/12/07/60-mac-spark/"/>


  <title> 『 Spark 』mac下Spark的安装与使用 | codingXiaxw's blog </title>
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">codingXiaxw's blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Life is short,just coding.</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            Contact
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                『 Spark 』mac下Spark的安装与使用
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-12-07T09:50:29+08:00" content="Dec 7 2016">
              Dec 7 2016
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/12/07/60-mac-spark/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/12/07/60-mac-spark/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/12/07/60-mac-spark/" class="leancloud_visitors" data-flag-title="『 Spark 』mac下Spark的安装与使用">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">visitors </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>每次接触一个新的知识之前我都抱有恐惧之心，因为总认为自己没有接触到的知识都很高大上，比如上篇介绍到的<a href="http://codingxiaxw.cn/2016/12/06/59-mac-hadoop/">Hadoop的安装与使用</a>与本篇要介绍的Spark,其实在自己真正琢磨以后才发现本以为高大上的知识其实也不过如此。<a id="more"></a></p>
<p>由于Spark是最新火起来的处理大数据的框架，国内教程资源少之甚少，所以本篇文章是本人在看了<a href="http://spark.apache.org/docs/latest/quick-start.html" target="_blank" rel="external">Spark官网的快速入门</a>教程后总结下来的经验，由于Spark同Hadoop一样可以运行在多种模式下，而本人又比较穷只有一台电脑，所以本篇文章为大家介绍如何在mac系统的本地模式下安装Spark以及安装后如何用Spark来进行交互式分析。  </p>
<p>本文结构:前部分介绍Spark的一点点(详情介绍请自行google)基础概念以及安装过程，后部分通过一个demo让大家快速学会使用Spark基本Api。</p>
<h2 id="1-Spark的运行模式"><a href="#1-Spark的运行模式" class="headerlink" title="1.Spark的运行模式"></a>1.Spark的运行模式</h2><p>在正式安装Spark之前，先给大家介绍下Spark可以在哪几种模式下运行。同上篇<a href="http://codingxiaxw.cn/2016/12/06/59-mac-hadoop/">Hadoop的安装与使用</a>中介绍的Hadoop可以运行在其3种模式中的任意一种模式之上，Spark也可以运行在多种模式之上，主要有以下4种运行模式:  </p>
<ul>
<li>1.<code>local</code>: 本地单进程模式，用于本地开发测试Spark代码。</li>
<li>2.<code>standalone</code>:分布式集群模式，Master-Worker架构，Master负责调度，Worker负责具体Task的执行。</li>
<li>3.<code>on yarn/mesos</code>:运行在yarn/mesos等资源管理框架之上，yarn/mesos提供资源管理，spark提供计算调度，并可与其他计算框架(如MapReduce/MPI/Storm)共同运行在同一个集群之上。</li>
<li>4.<code>on cloud(EC2)</code>: 运行在AWS的EC2之上</li>
</ul>
<p>由于博主比较穷，所以下面为大家介绍本地模式下Spark的安装与使用。</p>
<h2 id="2-Spark的安装"><a href="#2-Spark的安装" class="headerlink" title="2.Spark的安装"></a>2.Spark的安装</h2><h3 id="2-1准备工作"><a href="#2-1准备工作" class="headerlink" title="2.1准备工作"></a>2.1准备工作</h3><p><strong>第一步:</strong>安装Java JDK 1.7及以上版本，并配置好环境变量。本电脑安装的jdk是1.7.0_79版本的。  </p>
<p><strong>第二步:</strong>安装Hadoop。本电脑安装的Hadoop是2.7.3版本的。</p>
<p><strong>疑惑:</strong>上篇文章说到可以不学Hadoop直接学习Spark，那为什么还要安装Hadoop?亲，我的意思是不用学习Hadoop的相关知识例如它的API啥的，但是没说不用先搭建Hadoop的环境呀！<br><strong>合理解释:</strong>Spark会用到HDFS与YARN，因此请先安装Hadoop，关于Hadoop的安装请参考我的上篇博文<a href="http://codingxiaxw.cn/2016/12/06/59-mac-hadoop/">mac下Hadoop的安装与使用</a>，在此就不再复述。  </p>
<p><strong>第三步:</strong>安装Scala 2.9.3以上版本。这里介绍下Scala在mac下的安装与环境变量的配置。点击链接进入<a href="http://www.scala-lang.org/download/" target="_blank" rel="external">scala官方网站</a>的下载页，下载2.11.8版本(第一次操作的时候我下载了最新版2.12.1，后来测试spark-shell命令时发现最新版本的scala与1.7版本的jdk不兼容，所以后来换成了2.11.8版本)的Scala:<br><img src="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-07%20%E4%B8%8B%E5%8D%883.27.59.png" alt="">  </p>
<p>点击图上下载链接会自动将scala下载到Dowmloads目录下，文件名为:<code>scala-2.12.1.tgz</code>，还有一种下载方法就是直接在命令行使用homebrew命令(作为一个Linux开发人员我建议使用这种方式)进行下载:<code>brew install scala</code>，该命令会自动帮你把scala下载到<code>/usr/local</code>目录下。使用在官网点击链接下载的方式的话，我们也要将该scala文件加到<code>/usr/local</code>目录下，你可以直接拷贝过去，当然作为一个Linux开发人员你可以直接使用一条命令完成将该压缩包进行<strong>解压</strong>并<strong>移动</strong>到<code>/usr/local/</code>目录下:<code>sudo tar -zxf ~/downloads/scala-2.12.1.tgz -C /usr/local/</code>，然后使用命令<code>cd /usr/local</code>进入到该目录下，由于解压后的文件名为:<code>scala-2.12.1</code>，所以为了之后配置的方便我们使用命令:<code>sudo mv ./scala-2.12.1 ./scala</code>将文件名修改为scala。因为该目录属于管理员级别的目录所以如果当前用户不是管理员的话应该在命令前面使用<code>sudo</code>关键字表示使用管理员权限。  </p>
<p>这样scala的安装便完成，但是还要配置scala的环境变量，使用命令:<code>sudo vim ./etc/profile</code>打开系统中配置环境变量的文件，在里面添加如下内容:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export SCALA_HOME=/usr/local/scala</span><br><span class="line">export PATH=$PATH:$SCALA_HOME/bin</span><br></pre></td></tr></table></figure></p>
<p>然后<code>:wq!</code>保存并退出该文件，输入命令使该文件的内容立刻生效:<code>source /etc/profile</code>，接下来在(根目录下)命令行输入:<code>scala</code>并敲击回车，看到控制台打印如下信息说明我们的scala安装并成功配置了环境变量:<img src="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-07%20%E4%B8%8B%E5%8D%884.50.39.png" alt="">  </p>
<p>图中信息即表明我们使用的scala版本为2.11.8，jdk版本为1.7.0_79。</p>
<p>使用命令行快捷键<code>control+c</code>或者<code>:quit</code>退出scala shell环境(网上教程有说使用exit命令可以退出scala shell环境，我试了但貌似不行)。</p>
<p><strong>疑惑:</strong>既然Spark提供了Scala、Python、Java三种程序设计语言的API，那么我直接用java不就好了，为什么还要下载Scala呢？是因为等会我们会使用Spark shell连接到Spark引擎进行交互式数据分析，而Spark shell只支持Scala和Python两种语言。Java不支持交互式的Shell，因此这一功能暂未在Java语言中实现(当然你也可以不使用shell编程，直接在IDE中用java编程语言连接到Spark引擎进行交互式数据分析也是可以的)。所以建议大家还是老老实实在电脑上面下载好scala并配置好环境变量，反正也占不了多大空间啊，而且万一哪天用到这东西了呢?所以下面我都是采用的scala支持的shell来配置的Spark，之后我也会使用scala运行spark-shell进行交互式数据分析的一个小示例带大家快速入门。</p>
<p>准备好如上环境后，接下来就可以进行Spark的安装与相关配置操作了。  </p>
<h3 id="2-2安装Spark并配置"><a href="#2-2安装Spark并配置" class="headerlink" title="2.2安装Spark并配置"></a>2.2安装Spark并配置</h3><p>接下来才是正题，进入<a href="http://spark.apache.org/downloads.html" target="_blank" rel="external">Apache Spark官方网站</a>进行Spark的下载，看到如下页面:<img src="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-07%20%E4%B8%8A%E5%8D%8811.33.53.png" alt="">  </p>
<p>第2条你要是选择的是Hadoop2.7的话，你要保证你之前安装的Hadoop版本也是2.7版本。选择第4条的下载链接即可(当然你也可以直接用Homebrew命令进行下载)，系统会将下好的文件放在Dowmloads文件目录下，文件名为:<code>spark-2.0.2-bin-hadoop2.7.tgz</code>，同scala的安装方法一样，我们使用命令:<code>sudo tar -zxf ~/Dowmloads/spark-2.0.2-bin-hadoop2.7.tgz -C /usr/local/</code>直接将该压缩包解压并移动到<code>/usr/local/</code>目录下，然后我们<code>cd /usr/local</code>进入到<code>/usr/local</code>目录下，使用命令更改该目录下的spark文件名:<code>sudo mv ./spark-2.0.2-bin-hadoop2.7 ./spark</code>将文件名改为<code>spark</code>。  </p>
<p>经过上述步骤从官网下载到Spark的文件，这样我们便完成了Spark的安装，但是Spark也是要进行相应的环境变量配置的，所以接下来我们进行Spark环境变量的配置。  </p>
<p>使用命令:<code>sudo vim /etc/profile</code>，在文件中加入Spark的环境变量:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export SPARK_HOME=/usr/local/spark</span><br><span class="line">export PATH=$PATH:$SPARK_HOME/bin</span><br></pre></td></tr></table></figure></p>
<p>然后我们进入到Spark目录的conf配置文件中:<code>cd /usr/local/spark/conf</code>，执行命令:<code>cp spark-env.sh.template spark-env.sh</code>将spark-env.sh.template拷贝一份，然后打开拷贝后的spark-env.sh文件:<code>vim spark-env.sh</code>，在里面加入如下内容:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export SCALA_HOME=/usr/local/scala</span><br><span class="line"></span><br><span class="line">export SPARK_MASTER_IP=localhost</span><br><span class="line"></span><br><span class="line">export SPARK_WORKER_MEMORY=4g</span><br></pre></td></tr></table></figure></p>
<p>这样我们便完成了Spark环境变量的配置，接下来测试测试一下Spark,在根目录(因为我们配置了spark环境变量，所以可以直接在根目录)下输入命令:<code>spark-shell</code>，看到控制台输出如下信息:<br><img src="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-07%20%E4%B8%8B%E5%8D%883.56.26.png" alt="">  </p>
<p>恭喜你，尽情享受Spark吧。</p>
<h2 id="3-安装过程出现的问题分析"><a href="#3-安装过程出现的问题分析" class="headerlink" title="3.安装过程出现的问题分析"></a>3.安装过程出现的问题分析</h2><p>1.运行<code>spark-shell</code>命令时控制台出现:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">..我忘了是啥报错了.connection out.中间报错信息是这个..</span><br></pre></td></tr></table></figure></p>
<p>的错误，说明没有配置SSH，配置SSH请参考我上篇文章中Hadoop安装的配置过程。</p>
<p>2.运行命令:<code>scala</code>时控制台出现:<br><img src="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-07%20%E4%B8%8B%E5%8D%883.59.58.png" alt="">  </p>
<p>的错误信息，表示scala没有成功安装，或者安装的scala与jdk不兼容，所以这里我建议你们就按本教程的2.11.8scala版本与1.7jdk版本来操作吧。这些坑我都试过了，所以才能为你们总结经验。(大哭脸)</p>
<p>3.其他错误，有以下原因，你们一定要一一进行检查:  </p>
<ul>
<li><p>1.关于JDK:JDK版本不对，所以我建议大家用1.7;或者是JDK版本正确但是没有成功配置它的环境变量，我配置时更改了两个文件的环境变量:一个是<code>/etc/profile</code>目录下的，一个是<code>.bash_profile</code>文件中的，配置环境变量信息如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure>
</li>
<li><p>2.关于scala:Scala版本不对，所以我建议大家用2.11.8;或者是没有成功配置scala的环境变量，配置环境变量按照文中介绍的即可。</p>
</li>
<li>3.Hadoop版本与Spark版本不兼容:所以大家在Spark官网下载Spark的时候一定要注意下载Spark时选择的第二条信息的Hadoop版本要与电脑上面已经安装的Hadoop一致才行。</li>
</ul>
<h2 id="4-快速入门Spark基础Api"><a href="#4-快速入门Spark基础Api" class="headerlink" title="4.快速入门Spark基础Api"></a>4.快速入门Spark基础Api</h2><p>这里我介绍两种使用Spark基础Api的方式，一种是在spark-shell中进行简单的测试，一种是在开发工具IDEA中进行代码的编写来教大家快速学习Spark基础API。  </p>
<h3 id="4-1使用spark-shell完成单词统计功能"><a href="#4-1使用spark-shell完成单词统计功能" class="headerlink" title="4.1使用spark-shell完成单词统计功能"></a>4.1使用spark-shell完成单词统计功能</h3><p>由于spark-shell只支持scala和python两种语言的编写，不支持Java，所以我在spark-shell中通过scala的语法来进行简单测试。  </p>
<p>在配置好Spark环境变量之后，我们打开命令行，直接在当前用户目录下输入命令<code>spark-shell</code>进入scala编写环境(当然前提是你首先使用命令<code>start-all.sh</code>命令开启了Spark):<img src="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-10%20%E4%B8%8B%E5%8D%882.11.20.png" alt="">  </p>
<p>我们从 <code>/usr/local/spark/README.md</code> 文件新建一个 RDD，代码如下（本文出现的 Spark 交互式命令代码中，第一行为代码及其解释，第二行及以后是控制台返回的结果):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val textFile = sc.textFile(&quot;file:///usr/local/spark/README.md&quot;)</span><br><span class="line">&gt;textFile: org.apache.spark.rdd.RDD[String] = file:///usr/local/spark/README.md MapPartitionsRDD[1] at textFile at &lt;console&gt;:24</span><br></pre></td></tr></table></figure></p>
<p>代码中通过 <code>file://</code> 前缀或者不加 <code>file://</code> 前缀表示指定读取本地文件。如果你这里传入的路径写的是HDFS上的文件路径，例如<code>hdfs://远程主机名:Hadoop端口号我/文件名</code>代表你要是读取的是 HDFS 中的文件，你需要先上传文件到 HDFS 中(至于如何上传，后面的demo中我们会进行讲解)，否则会有<code>org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://localhost:9000/user/hadoop/README.md</code>的错误。这里我们就以读取本地文件进行讲解。  </p>
<p>RDDs 支持两种类型的操作:1.actions: 在数据集上运行计算后返回值。2.transformations: 转换, 从现有数据集上创建一个新的数据集。  </p>
<p>使用上述命令创建好的RDD对象,下面我们就来通过该对象演示 count() 和 first() 操作:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">textFile.count()  // RDD 中的 item 数量，对于文本文件，就是总行数</span><br><span class="line">&gt;res0: Long = 95</span><br><span class="line"> </span><br><span class="line">textFile.first() // RDD 中的第一个 item，对于文本文件，就是第一行内容</span><br><span class="line">&gt;res1: String = # Apache Spark</span><br></pre></td></tr></table></figure></p>
<p>接着演示 transformation，通过 filter transformation 来返回一个新的 RDD，代码如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val linesWithSpark = textFile.filter(line =&gt; line.contains(&quot;Spark&quot;))   // 筛选出包含 Spark 的行</span><br><span class="line">&gt;linesWithSpark: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at filter at &lt;console&gt;:26</span><br><span class="line"> </span><br><span class="line">linesWithSpark.count()       // 统计行数</span><br><span class="line">&gt;res4: Long = 17</span><br></pre></td></tr></table></figure></p>
<p>上述我们完成了RDD的简单计算，而RDD 的 actions 和 transformations 其实可用在更复杂的计算中，例如通过如下代码可以找到包含单词最多的那一行内容共有几个单词:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">textFile.map(line =&gt; line.split(&quot; &quot;).size).reduce((a, b) =&gt; if (a &gt; b) a else b)</span><br><span class="line">&gt;res1: Int = 22</span><br></pre></td></tr></table></figure></p>
<p>代码首先将每一行内容 map 为一个整数，这将创建一个新的 RDD，并在这个 RDD 中执行 reduce 操作，找到最大的数。map()、reduce() 中的参数是 Scala 的函数字面量（function literals，也称为闭包 closures），并且可以使用语言特征或 Scala/Java 的库。例如，通过使用 Math.max() 函数（需要导入 Java 的 Math 库），可以使上述代码更容易理解:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import java.lang.Math //先导入Math函数</span><br><span class="line"> </span><br><span class="line">textFile.map(line =&gt; line.split(&quot; &quot;).size).reduce((a, b) =&gt; Math.max(a, b))</span><br><span class="line">&gt;res6: Int = 14</span><br></pre></td></tr></table></figure></p>
<p>Hadoop MapReduce 是常见的数据流模式，在 Spark 中同样可以实现（下面这个例子也就是 WordCount）:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val wordCounts = textFile.flatMap(line =&gt; line.split(&quot; &quot;)).map(word =&gt; (word, 1)).reduceByKey((a, b) =&gt; a + b)   // 实现单词统计</span><br><span class="line">&gt;wordCounts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[4] at reduceByKey at &lt;console&gt;:29</span><br><span class="line"> </span><br><span class="line">wordCounts.collect()    // 输出单词统计结果</span><br><span class="line">&gt;res7: Array[(String, Int)] = Array((package,1), (For,2), (Programs,1), (processing.,1), (Because,1), (The,1)...)</span><br></pre></td></tr></table></figure></p>
<p>上述我们通过spark-shell完成单词的统计简单对我们spark的基础Api进行了熟悉，采用的是scala语言，由于我是一个java开发人员，所以接下来就在开发工具IDEA中通过编写Java代码来实现HDFS中某个路径下文件内容中单词的统计功能。</p>
<h3 id="4-2在IDEA中编写Java代码完成HDFS中某个文件中的单词统计功能"><a href="#4-2在IDEA中编写Java代码完成HDFS中某个文件中的单词统计功能" class="headerlink" title="4.2在IDEA中编写Java代码完成HDFS中某个文件中的单词统计功能"></a>4.2在IDEA中编写Java代码完成HDFS中某个文件中的单词统计功能</h3><p>既然要统计HDFS中某个文件中的单词，那么我们首先要将文件上传到HDFS上吧！如何上传?听我慢慢道来。  </p>
<p>使用命令<code>:quit</code>退出scala命令环境，首先在本地电脑的当前用户目录下创建一个文件，我这里创建了一个叫hello的txt文件，里面写上内容<code>hello world hello you  hello  hello 
，内容可以随便打啦</code>，然后输入hadoop的命令(关于Hadoop的更多命令请自行google):<code>hadoop fs -put ~/hello /</code>，实现将本机目录下的hello文件推至远程主机的根目录下，然后便可以开始编写我们的java代码了。  </p>
<p>使用IDEA创建一个Maven项目(便于管理我们的jar包嘛！)，在pom.xml中添加上Spark相应jar包坐标:<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span><br><span class="line">  <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>cn.codingxiaxw.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-mvn<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">packaging</span>&gt;</span>war<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>spark-mvn Maven Webapp<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.apache.org<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span> <span class="comment">&lt;!-- Spark dependency --&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.0.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">finalName</span>&gt;</span>spark-mvn<span class="tag">&lt;/<span class="name">finalName</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.7<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.7<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>然后创建一个WordCount.java文件，代码如下:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Simple</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Pattern SPACE = Pattern.compile(<span class="string">" "</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//        if (args.length &lt; 1) &#123;</span></span><br><span class="line"><span class="comment">//            System.err.println("Usage: JavaWordCount &lt;file&gt;");</span></span><br><span class="line"><span class="comment">//            System.exit(1);</span></span><br><span class="line"><span class="comment">//        &#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建一个RDD对象</span></span><br><span class="line">        SparkConf conf=<span class="keyword">new</span> SparkConf().setAppName(<span class="string">"Simple"</span>).setMaster(<span class="string">"local"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建spark上下文对象，是数据的入口</span></span><br><span class="line">        JavaSparkContext spark=<span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取数据源</span></span><br><span class="line">        JavaRDD&lt;String&gt; lines = spark.textFile(<span class="string">"hdfs://localhost:8020/hello"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span><br><span class="line">         * 对于从数据源得到的DStream，用户可以在其基础上进行各种操作，</span><br><span class="line">         * 对于当前时间窗口内从数据源得到的数据首先进行分割，</span><br><span class="line">         * 然后利用Map和ReduceByKey方法进行计算，当然最后还有使用print()方法输出结果；</span><br><span class="line">         */</span></span><br><span class="line">        JavaRDD&lt;String&gt; words = lines.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Iterator&lt;String&gt; <span class="title">call</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> Arrays.asList(SPACE.split(s)).iterator();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//使用RDD的map和reduce方法进行计算</span></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; ones = words.mapToPair(</span><br><span class="line">                <span class="keyword">new</span> PairFunction&lt;String, String, Integer&gt;() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title">call</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">                        <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(s, <span class="number">1</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; counts = ones.reduceByKey(</span><br><span class="line">                <span class="keyword">new</span> Function2&lt;Integer, Integer, Integer&gt;() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> Integer <span class="title">call</span><span class="params">(Integer i1, Integer i2)</span> </span>&#123;</span><br><span class="line">                        <span class="keyword">return</span> i1 + i2;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line"></span><br><span class="line">        List&lt;Tuple2&lt;String, Integer&gt;&gt; output = counts.collect();</span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;?,?&gt; tuple : output) &#123;</span><br><span class="line">            <span class="comment">//输出计算结果</span></span><br><span class="line">            System.out.println(tuple._1() + <span class="string">": "</span> + tuple._2());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>各行代码意思见代码旁的注释，上述代码都是从官方文档抄的，但是貌似要注释掉官方文档的:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//        if (args.length &lt; 1) &#123;</span></span><br><span class="line"><span class="comment">//            System.err.println("Usage: JavaWordCount &lt;file&gt;");</span></span><br><span class="line"><span class="comment">//            System.exit(1);</span></span><br><span class="line"><span class="comment">//        &#125;</span></span><br></pre></td></tr></table></figure></p>
<p>然后运行程序，控制台输出结果如下图:<br><img src="http://od2xrf8gr.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-12-10%20%E4%B8%8B%E5%8D%882.42.45.png" alt=""></p>
<p>成功统计出HDFS上文件内容的单词个数。到此，我们便简单熟悉了Spark的相关API，下篇文章我将介绍通过Spark的<a href="http://codingxiaxw.cn/2016/12/10/61-spark-streaming/">Streaming Api实现对流式数据的处理</a>为大家介绍Spark中Streming库的相关Api操作。</p>
<h2 id="5-联系"><a href="#5-联系" class="headerlink" title="5.联系"></a>5.联系</h2><p>  If you have some questions after you see this article,you can tell your doubts in the comments area or you can find some info by  clicking these links.</p>
<ul>
<li><p><a href="http://codingxiaxw.cn">Blog@codingXiaxw’s blog</a></p>
</li>
<li><p><a href="http://weibo.com/u/5023661572" target="_blank" rel="external">Weibo@codingXiaxw</a></p>
</li>
<li><p><a href="https://www.zhihu.com/people/xia-xun-wu-56/" target="_blank" rel="external">Zhihu@codingXiaxw</a>  </p>
</li>
<li><a href="https://github.com/codingXiaxw" target="_blank" rel="external">Github@codingXiaxw</a></li>
</ul>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="http://od2xrf8gr.bkt.clouddn.com/61591357B4886B1E1F949CBB68322C34.jpg" alt="codingXiaxw WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
    </div>
  </div>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Spark/" rel="tag">#Spark</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/12/06/59-mac-hadoop/" rel="next" title="『 Hadoop 』mac下Hadoop的安装与使用">
                <i class="fa fa-chevron-left"></i> 『 Hadoop 』mac下Hadoop的安装与使用
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/12/10/61-spark-streaming/" rel="prev" title="『 Spark 』使用Spark Streaming处理流式数据">
                『 Spark 』使用Spark Streaming处理流式数据 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2016/12/07/60-mac-spark/"
           data-title="『 Spark 』mac下Spark的安装与使用" data-url="http://codingxiaxw.cn/2016/12/07/60-mac-spark/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://od2xrf8gr.bkt.clouddn.com/%E5%A4%B4%E5%83%8F.jpg"
               alt="codingXiaxw" />
          <p class="site-author-name" itemprop="name">codingXiaxw</p>
          <p class="site-description motion-element" itemprop="description">Life is short,just coding.</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">63</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">34</span>
                <span class="site-state-item-name">categories</span>
              
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">32</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/codingXiaxw" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/5023661572?from=hissimilar_home&refer_flag=1005050003_" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.zhihu.com//people/e9f78fa34b8002652811ac348da3f671" target="_blank" title="Zhihu">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  Zhihu
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Spark的运行模式"><span class="nav-number">1.</span> <span class="nav-text">1.Spark的运行模式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Spark的安装"><span class="nav-number">2.</span> <span class="nav-text">2.Spark的安装</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1准备工作"><span class="nav-number">2.1.</span> <span class="nav-text">2.1准备工作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2安装Spark并配置"><span class="nav-number">2.2.</span> <span class="nav-text">2.2安装Spark并配置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-安装过程出现的问题分析"><span class="nav-number">3.</span> <span class="nav-text">3.安装过程出现的问题分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-快速入门Spark基础Api"><span class="nav-number">4.</span> <span class="nav-text">4.快速入门Spark基础Api</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1使用spark-shell完成单词统计功能"><span class="nav-number">4.1.</span> <span class="nav-text">4.1使用spark-shell完成单词统计功能</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2在IDEA中编写Java代码完成HDFS中某个文件中的单词统计功能"><span class="nav-number">4.2.</span> <span class="nav-text">4.2在IDEA中编写Java代码完成HDFS中某个文件中的单词统计功能</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-联系"><span class="nav-number">5.</span> <span class="nav-text">5.联系</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">codingXiaxw</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"codingXiaxw"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  






  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = false;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = decodeURIComponent(data.url);
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title >= 0 || index_content >= 0 ){
                                isMatch = true;
								if (i == 0) {
                                    first_occur = index_content;
                                }
                            } 
							
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("G9m3Gnu7lbpyUM0MJAyJFK9g-gzGzoHsz", "E72YIgigcKXLV4XC5x7GgYDt");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  


</body>
</html>
